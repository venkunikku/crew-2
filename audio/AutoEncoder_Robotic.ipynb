{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Following steps are data preprocessing and can checked the autoencoder model after load the pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import soundfile as sf\n",
    "import wave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the original sound files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = pd.read_csv('../training/UrbanSound8K/metadata/metadata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Combines all noise files into one\n",
    "```\n",
    "merge-noise.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "noise_dir = \"../noise/\"\n",
    "\n",
    "infiles = os.listdir(noise_dir)\n",
    "outfile = noise_dir + \"combined-noise.wav\"\n",
    "\n",
    "combined_data = []\n",
    "for infile in infiles:\n",
    "    w = wave.open(noise_dir + infile, 'rb')\n",
    "    combined_data.append([w.getparams(), w.readframes(w.getnframes())])\n",
    "    w.close()\n",
    "\n",
    "output = wave.open(outfile, 'wb')\n",
    "output.setparams(combined_data[0][0])\n",
    "output.writeframes(combined_data[0][1])\n",
    "output.writeframes(combined_data[1][1])\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Takes in the noise files and spits them out at the specified sample rate\n",
    "```\n",
    "downsample-noise.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kailf\\Python_code\\UChicago\\Capstone\\noise\\combined-noise.wav\n",
      "combined-noise.wav\n",
      "C:\\Users\\kailf\\Python_code\\UChicago\\Capstone\\noise\\noise (1).wav\n",
      "noise (1).wav\n",
      "C:\\Users\\kailf\\Python_code\\UChicago\\Capstone\\noise\\noise (2).wav\n",
      "noise (2).wav\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import os\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "target = '../noise_downsampled'\n",
    "\n",
    "files = librosa.util.find_files('../noise', ext='wav')\n",
    "\n",
    "for file in files:\n",
    "    basename = os.path.basename(file)\n",
    "    print(file)\n",
    "    print(basename)\n",
    "    y, sr = librosa.load(file, sr=44100, mono = True)\n",
    "    sf.write((target + \"/\" + basename), y, sr, subtype = 'PCM_16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Cuts the merged noise file into n-second slices\n",
    "```\n",
    "slice-noise.py\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split at [0.0:4.0] s\n",
      "split at [4.0:8.0] s\n",
      "split at [8.0:12.0] s\n",
      "split at [12.0:16.0] s\n",
      "split at [16.0:20.0] s\n",
      "split at [20.0:24.0] s\n",
      "split at [24.0:28.0] s\n",
      "split at [28.0:32.0] s\n",
      "split at [32.0:36.0] s\n",
      "split at [36.0:40.0] s\n",
      "split at [40.0:44.0] s\n",
      "split at [44.0:48.0] s\n",
      "split at [48.0:52.0] s\n",
      "split at [52.0:56.0] s\n",
      "split at [56.0:60.0] s\n",
      "split at [60.0:64.0] s\n",
      "split at [64.0:68.0] s\n",
      "split at [68.0:72.0] s\n",
      "split at [72.0:76.0] s\n",
      "split at [76.0:80.0] s\n",
      "split at [80.0:84.0] s\n",
      "split at [84.0:88.0] s\n",
      "split at [88.0:92.0] s\n",
      "split at [92.0:96.0] s\n",
      "split at [96.0:100.0] s\n",
      "split at [100.0:104.0] s\n",
      "split at [104.0:108.0] s\n",
      "split at [108.0:112.0] s\n",
      "split at [112.0:116.0] s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kailf\\Anaconda3\\lib\\site-packages\\pydub\\utils.py:165: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "import numpy as np\n",
    "\n",
    "noise_downsampled_dir = \"../noise_downsampled/\"\n",
    "\n",
    "audio_file = noise_downsampled_dir + \"combined-noise.wav\"\n",
    "audio = AudioSegment.from_wav(audio_file)\n",
    "list_of_timestamps = list(np.arange(4,120,4))  #and so on in *seconds*\n",
    "\n",
    "start = 0\n",
    "for  idx,t in enumerate(list_of_timestamps):\n",
    "    #break loop if at last element of list\n",
    "    if idx == len(list_of_timestamps):\n",
    "        break\n",
    "\n",
    "    end = t * 1000 #pydub works in millisec\n",
    "    print(\"split at [{}:{}] s\".format(start/1000, end/1000))\n",
    "    audio_chunk = audio[start:end]\n",
    "    audio_chunk.export(noise_downsampled_dir + \"noise_chunk_{}.wav\".format(end/1000), format=\"wav\")\n",
    "\n",
    "    start = end  #pydub works in millisec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Take in training files and spit them out in a single directory at the specified sample rate\n",
    "```\n",
    "downsample-training.py\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use 44100 as the target sample rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "sr = 44100\n",
    "audio_class = []\n",
    "current_dir = '../training/UrbanSound8K/audio'\n",
    "target_dir = \"../training_downsampled\"\n",
    "\n",
    "for folder in os.listdir(current_dir):\n",
    "\t\n",
    "\tif folder != '.DS_Store':\n",
    " \n",
    "\t\tpath = os.path.join(current_dir, folder)\n",
    "\t\tfor filename in os.listdir(path):\n",
    "\t\t\tif filename != '.DS_Store':\t\n",
    "\t\t\t\ta,b = librosa.core.load(os.path.join(path, filename),sr=sr, mono=True)\n",
    "\t\t\t\tsf.write((target_dir + \"/\" + filename), a, b, subtype = 'PCM_16')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Randomly mix noise samples with training samples\n",
    "```\n",
    "mix-noises-training.py\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pydub import AudioSegment\n",
    "from random import seed\n",
    "from random import randint \n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "n_iterations = 2\n",
    "\n",
    "noise_downsampled_dir = '../noise_downsampled/'\n",
    "down_sampled_training_dir = '../training_downsampled/'\n",
    "#noise_downsampled_dir = '../noise_downsampled/'\n",
    "target_dir = '../mixed/'\n",
    "\n",
    "# delete all existing contents\n",
    "files = glob.glob(target_dir + '*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "# move clean downsampled files over\n",
    "for filename in glob.glob(os.path.join(down_sampled_training_dir, '*.*')):\n",
    "    shutil.copy(filename, target_dir)\n",
    "\n",
    "mixed_meta_data = pd.read_csv('../training/UrbanSound8K/metadata/metadata.csv')\n",
    "\n",
    "# read in noise files\n",
    "noise_chunks = []\n",
    "for i in os.listdir(noise_downsampled_dir):\n",
    "    if os.path.isfile(os.path.join(noise_downsampled_dir,i)) and 'noise_chunk' in i:\n",
    "        noise_chunks.append(i)\n",
    "\n",
    "# depends on the number of times you want to randomly mix each file\n",
    "for i in range(n_iterations):\n",
    "    \n",
    "    seed(i)\n",
    "\n",
    "    # for one iteration, fix each file in the training directory\n",
    "    for filename in os.listdir(down_sampled_training_dir):\n",
    "\n",
    "        if filename != \".DS_Store\":\n",
    "    \n",
    "            # get the downsampled training clip\n",
    "            file_path1 = os.path.join(down_sampled_training_dir, filename)\n",
    "            sound1 = AudioSegment.from_file(file_path1)\n",
    "\n",
    "            # random pick a noise chunk\n",
    "            random_int = randint(0, (len(noise_chunks)-1))\n",
    "            noise_file = noise_chunks[random_int]\n",
    "            file_path2 = os.path.join(noise_downsampled_dir, noise_file)\n",
    "            sound2 = AudioSegment.from_file(file_path2)\n",
    "        \n",
    "            # combine both sound files\n",
    "            combined = sound1.overlay(sound2)\n",
    "        \n",
    "            # export resulting wav to target dir\n",
    "            combined.export(target_dir + \"mixed_\" + str(i) + \"_\" + filename, format=\"wav\")\n",
    "\n",
    "            # update metadata\n",
    "            row = mixed_meta_data[mixed_meta_data['slice_file_name'] == filename]\n",
    "            mixed_meta_data = mixed_meta_data.append(row)\n",
    "            updated_row = mixed_meta_data.iloc[len(mixed_meta_data)-1].replace({mixed_meta_data.iloc[len(mixed_meta_data)-1,0]:\"mixed_%s_%s\" % (str(i),filename)})\n",
    "            mixed_meta_data.iloc[len(mixed_meta_data)-1] = updated_row\n",
    "\n",
    "            #print(\"length:\",len(mixed_meta_data)-1)\n",
    "            newname = \"mixed_%s_%s\" % (str(i), filename)\n",
    "            #print(\"newname:\",newname)\n",
    "            \n",
    "mixed_meta_data.to_csv(target_dir+'mixed_metadata.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "down\n"
     ]
    }
   ],
   "source": [
    "print('down')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the mixed sound file and loabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import librosa \n",
    "import scipy\n",
    "\n",
    "\n",
    "meta_data = pd.read_csv('../mixed/mixed_metadata.csv')\n",
    "\n",
    "x = []\n",
    "sr = []\n",
    "audio_class = []\n",
    "folder_name = '../mixed/'\n",
    "\n",
    "for filename in os.listdir(folder_name):\n",
    "    if filename != \"mixed_metadata.csv\":\n",
    "        file = os.path.join(folder_name, filename)\n",
    "        #print(file)\n",
    "\n",
    "        temp_sr, temp_x = scipy.io.wavfile.read(file)\n",
    "        #print(file)\n",
    "        x.append(temp_x)\n",
    "        sr.append(temp_sr)\n",
    "\n",
    "        temp_index = meta_data[meta_data['slice_file_name'] == filename].index\n",
    "        audio_class.append(meta_data['classID'][temp_index[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "down\n"
     ]
    }
   ],
   "source": [
    "print('down')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26196"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(audio_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26196"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26196"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f: array\n",
    "Array of sample frequencies.\n",
    "\n",
    "t: array\n",
    "Array of segment times.\n",
    "\n",
    "Z: array\n",
    "STFT of x. By default, the last axis of Zxx corresponds to the segment times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stft_sf = []\n",
    "stft_t = []\n",
    "stft_x = []\n",
    "#stft_sf, stft_t, stft_x = signal.stft(x[1], sr[1])\n",
    "\n",
    "for i in range(len(x)):\n",
    "    \n",
    "    f, t, Zx = signal.stft(x[i], sr[i])\n",
    "    if Zx.shape[1] == 1380:\n",
    "        stft_sf.append(f)    \n",
    "        stft_t.append(t)\n",
    "        stft_x.append(Zx)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21975, 21975, 21975)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stft_x), len(stft_sf), len(stft_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kailf\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['stft_x.sav']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "filename = 'stft_x.sav'\n",
    "joblib.dump(stft_x, filename)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_x.sav']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "filename = 'train_x.sav'\n",
    "joblib.dump(train_x, filename)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io.wavfile as wavfile\n",
    "import os\n",
    "\n",
    "from python_speech_features import mfcc, logfbank\n",
    "import tensorflow as tf\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "stft_x = joblib.load('stft_x.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.array(stft_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21975, 129, 1380)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del X_train_split_temp,  #X_train_split,  X_valid_split, X_test_split, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_split_temp, X_test_split = train_test_split(train_x, test_size=0.05,random_state= 220)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_split, X_valid_split = train_test_split(X_train_split_temp, test_size=0.2,\n",
    "                                   random_state= 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16700, 129, 1380), (4176, 129, 1380), (1099, 129, 1380))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_split.shape, X_valid_split.shape, X_test_split.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_len = train_x.shape[0]\n",
    "# train_len*0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_split = train_x[0:17580, :, :]\n",
    "# X_train_split.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4124, 129, 1380)"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_valid_split = train_x[17851:, :, :]\n",
    "# X_valid_split.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kailf\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\kailf\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\kailf\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\kailf\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\kailf\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\kailf\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import h5py\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense, BatchNormalization, Dropout\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = train_x.shape[1:3]\n",
    "layer1_dim = 256\n",
    "layer2_dim = 64\n",
    "layer3_dim = 32\n",
    "encoder_dim = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129, 1380)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_layer:  Tensor(\"input_1:0\", shape=(None, 129, 1380), dtype=float32)\n",
      "encoder1 Tensor(\"dense_1/Tanh:0\", shape=(None, 129, 256), dtype=float32)\n",
      "encoder2 Tensor(\"dense_2/Relu:0\", shape=(None, 129, 64), dtype=float32)\n",
      "encoder3 Tensor(\"dense_3/Relu:0\", shape=(None, 129, 32), dtype=float32)\n",
      "encoder4 Tensor(\"dense_4/Relu:0\", shape=(None, 129, 8), dtype=float32)\n",
      "decoder1 Tensor(\"dense_5/Tanh:0\", shape=(None, 129, 32), dtype=float32)\n",
      "decoder2 Tensor(\"dense_6/Tanh:0\", shape=(None, 129, 64), dtype=float32)\n",
      "decoder3 Tensor(\"dense_7/Tanh:0\", shape=(None, 129, 256), dtype=float32)\n",
      "decoder4 Tensor(\"dense_8/add:0\", shape=(None, 129, 1380), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(input_dim))\n",
    "\n",
    "encoder1 = Dense(layer1_dim, activation=\"tanh\", \n",
    "                activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "normalization1 = BatchNormalization()(encoder1)\n",
    "drop1 = Dropout(rate = 0.1)(normalization1)\n",
    "\n",
    "encoder2 = Dense(layer2_dim, activation=\"relu\")(drop1)\n",
    "normalization2 = BatchNormalization()(encoder2)\n",
    "drop2 = Dropout(rate = 0.1)(normalization2)\n",
    "\n",
    "encoder3 = Dense(layer3_dim, activation=\"relu\")(drop2)\n",
    "normalization3 = BatchNormalization()(encoder3)\n",
    "drop3 = Dropout(rate = 0.1)(normalization3)\n",
    "\n",
    "encoder4 = Dense(encoder_dim, activation=\"relu\")(drop3)\n",
    "normalization4 = BatchNormalization()(encoder4)\n",
    "drop4 = Dropout(rate = 0.1)(normalization4)\n",
    "\n",
    "decoder1 = Dense(layer3_dim, activation='tanh')(drop4)\n",
    "\n",
    "decoder2 = Dense(layer2_dim, activation='tanh')(decoder1)\n",
    "\n",
    "decoder3 = Dense(layer1_dim, activation='tanh')(decoder2)\n",
    "\n",
    "decoder4 = Dense(1380, activation='linear')(decoder3)\n",
    "\n",
    "print('input_layer: ',input_layer)\n",
    "print('encoder1',encoder1)\n",
    "print('encoder2',encoder2)\n",
    "print('encoder3',encoder3)\n",
    "print('encoder4',encoder4)\n",
    "print('decoder1',decoder1)\n",
    "print('decoder2',decoder2)\n",
    "print('decoder3',decoder3)\n",
    "print('decoder4',decoder4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 129, 1380)         0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 129, 256)          353536    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 129, 256)          1024      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 129, 256)          0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 129, 64)           16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 129, 64)           256       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 129, 64)           0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 129, 32)           2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 129, 32)           128       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 129, 32)           0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 129, 8)            264       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 129, 8)            32        \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 129, 8)            0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 129, 32)           288       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 129, 64)           2112      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 129, 256)          16640     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 129, 1380)         354660    \n",
      "=================================================================\n",
      "Total params: 747,468\n",
      "Trainable params: 746,748\n",
      "Non-trainable params: 720\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder = Model(inputs=input_layer, outputs=decoder4)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "down\n"
     ]
    }
   ],
   "source": [
    "print('down')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16700 samples, validate on 4176 samples\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kailf\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py:96: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return ops.EagerTensor(value, ctx.device_name, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16700/16700 [==============================] - 216s 13ms/step - loss: 93520.0215 - val_loss: 93606.8240\n",
      "Epoch 2/150\n",
      "16700/16700 [==============================] - 204s 12ms/step - loss: 93016.8319 - val_loss: 93117.8995\n",
      "Epoch 3/150\n",
      "16700/16700 [==============================] - 203s 12ms/step - loss: 92602.2565 - val_loss: 92711.6532\n",
      "Epoch 4/150\n",
      "16700/16700 [==============================] - 200s 12ms/step - loss: 92252.3714 - val_loss: 92366.4023\n",
      "Epoch 5/150\n",
      "16700/16700 [==============================] - 206s 12ms/step - loss: 91949.0585 - val_loss: 92068.4897\n",
      "Epoch 6/150\n",
      "16700/16700 [==============================] - 202s 12ms/step - loss: 91678.5436 - val_loss: 91794.9485\n",
      "Epoch 7/150\n",
      "16700/16700 [==============================] - 202s 12ms/step - loss: 91433.2043 - val_loss: 91537.3760\n",
      "Epoch 8/150\n",
      "16700/16700 [==============================] - 197s 12ms/step - loss: 91201.6653 - val_loss: 91303.0910\n",
      "Epoch 9/150\n",
      "16700/16700 [==============================] - 213s 13ms/step - loss: 90992.3872 - val_loss: 91084.2524\n",
      "Epoch 10/150\n",
      "16700/16700 [==============================] - 209s 13ms/step - loss: 90789.3137 - val_loss: 90872.3147\n",
      "Epoch 11/150\n",
      "16700/16700 [==============================] - 221s 13ms/step - loss: 90597.2035 - val_loss: 90668.4802\n",
      "Epoch 12/150\n",
      "16700/16700 [==============================] - 207s 12ms/step - loss: 90407.5544 - val_loss: 90469.7084\n",
      "Epoch 13/150\n",
      "16700/16700 [==============================] - 199s 12ms/step - loss: 90228.3039 - val_loss: 90274.0743\n",
      "Epoch 14/150\n",
      "16700/16700 [==============================] - 196s 12ms/step - loss: 90052.6063 - val_loss: 90079.3909\n",
      "Epoch 15/150\n",
      "16700/16700 [==============================] - 207s 12ms/step - loss: 89877.6464 - val_loss: 89894.5477\n",
      "Epoch 16/150\n",
      "16700/16700 [==============================] - 201s 12ms/step - loss: 89707.3313 - val_loss: 89718.1269\n",
      "Epoch 17/150\n",
      "16700/16700 [==============================] - 196s 12ms/step - loss: 89544.1042 - val_loss: 89549.4336\n",
      "Epoch 18/150\n",
      "16700/16700 [==============================] - 192s 12ms/step - loss: 89378.0170 - val_loss: 89370.7969\n",
      "Epoch 19/150\n",
      "16700/16700 [==============================] - 214s 13ms/step - loss: 89219.6221 - val_loss: 89192.9378\n",
      "Epoch 20/150\n",
      "16700/16700 [==============================] - 206s 12ms/step - loss: 89067.4039 - val_loss: 89029.3509\n",
      "Epoch 21/150\n",
      "16700/16700 [==============================] - 207s 12ms/step - loss: 88915.4795 - val_loss: 88865.8320\n",
      "Epoch 22/150\n",
      "16700/16700 [==============================] - 211s 13ms/step - loss: 88756.9534 - val_loss: 88701.4957\n",
      "Epoch 23/150\n",
      "16700/16700 [==============================] - 193s 12ms/step - loss: 88608.2304 - val_loss: 88538.8470\n",
      "Epoch 24/150\n",
      "16700/16700 [==============================] - 185s 11ms/step - loss: 88458.9236 - val_loss: 88371.9961\n",
      "Epoch 25/150\n",
      "16700/16700 [==============================] - 166s 10ms/step - loss: 88314.1146 - val_loss: 88221.5058\n",
      "Epoch 26/150\n",
      "16700/16700 [==============================] - 174s 10ms/step - loss: 88177.0464 - val_loss: 88068.3594\n",
      "Epoch 27/150\n",
      "16700/16700 [==============================] - 166s 10ms/step - loss: 88028.2368 - val_loss: 87911.4481\n",
      "Epoch 28/150\n",
      "16700/16700 [==============================] - 170s 10ms/step - loss: 87877.4645 - val_loss: 87753.5907\n",
      "Epoch 29/150\n",
      "16700/16700 [==============================] - 167s 10ms/step - loss: 87747.5577 - val_loss: 87603.9870\n",
      "Epoch 30/150\n",
      "16700/16700 [==============================] - 175s 10ms/step - loss: 87608.6334 - val_loss: 87464.2850\n",
      "Epoch 31/150\n",
      "16700/16700 [==============================] - 175s 10ms/step - loss: 87488.8588 - val_loss: 87320.1360\n",
      "Epoch 32/150\n",
      "16700/16700 [==============================] - 177s 11ms/step - loss: 87343.3186 - val_loss: 87177.0170\n",
      "Epoch 33/150\n",
      "16700/16700 [==============================] - 170s 10ms/step - loss: 87209.5824 - val_loss: 87033.2352\n",
      "Epoch 34/150\n",
      "16700/16700 [==============================] - 171s 10ms/step - loss: 87090.5036 - val_loss: 86875.5346\n",
      "Epoch 35/150\n",
      "16700/16700 [==============================] - 166s 10ms/step - loss: 86947.7097 - val_loss: 86726.9827\n",
      "Epoch 36/150\n",
      "16700/16700 [==============================] - 175s 10ms/step - loss: 86820.6990 - val_loss: 86594.3300\n",
      "Epoch 37/150\n",
      "16700/16700 [==============================] - 168s 10ms/step - loss: 86687.6196 - val_loss: 86451.1048\n",
      "Epoch 38/150\n",
      "16700/16700 [==============================] - 176s 11ms/step - loss: 86550.6804 - val_loss: 86303.7567\n",
      "Epoch 39/150\n",
      "16700/16700 [==============================] - 168s 10ms/step - loss: 86420.5700 - val_loss: 86165.1808\n",
      "Epoch 40/150\n",
      "16700/16700 [==============================] - 168s 10ms/step - loss: 86307.4018 - val_loss: 86021.8193\n",
      "Epoch 41/150\n",
      "16700/16700 [==============================] - 178s 11ms/step - loss: 86181.9924 - val_loss: 85894.4966\n",
      "Epoch 42/150\n",
      "16700/16700 [==============================] - 163s 10ms/step - loss: 86061.1168 - val_loss: 85754.0872\n",
      "Epoch 43/150\n",
      "16700/16700 [==============================] - 168s 10ms/step - loss: 85940.8382 - val_loss: 85618.9312\n",
      "Epoch 44/150\n",
      "16700/16700 [==============================] - 171s 10ms/step - loss: 85808.8486 - val_loss: 85480.5763\n",
      "Epoch 45/150\n",
      "16700/16700 [==============================] - 178s 11ms/step - loss: 85690.1905 - val_loss: 85344.1697\n",
      "Epoch 46/150\n",
      "16700/16700 [==============================] - 174s 10ms/step - loss: 85568.3041 - val_loss: 85203.2751\n",
      "Epoch 47/150\n",
      "16700/16700 [==============================] - 173s 10ms/step - loss: 85438.1636 - val_loss: 85066.0999\n",
      "Epoch 48/150\n",
      "16700/16700 [==============================] - 166s 10ms/step - loss: 85307.2786 - val_loss: 84919.3716\n",
      "Epoch 49/150\n",
      "16700/16700 [==============================] - 173s 10ms/step - loss: 85182.6142 - val_loss: 84783.6879\n",
      "Epoch 50/150\n",
      "16700/16700 [==============================] - 166s 10ms/step - loss: 85060.4458 - val_loss: 84642.6081\n",
      "Epoch 51/150\n",
      "16700/16700 [==============================] - 184s 11ms/step - loss: 84950.4448 - val_loss: 84507.7324\n",
      "Epoch 52/150\n",
      "16700/16700 [==============================] - 174s 10ms/step - loss: 84810.0146 - val_loss: 84380.7431\n",
      "Epoch 53/150\n",
      "16700/16700 [==============================] - 163s 10ms/step - loss: 84692.0901 - val_loss: 84243.5497\n",
      "Epoch 54/150\n",
      "16700/16700 [==============================] - 181s 11ms/step - loss: 84570.5256 - val_loss: 84107.6868\n",
      "Epoch 55/150\n",
      "16700/16700 [==============================] - 172s 10ms/step - loss: 84450.2496 - val_loss: 83973.6712\n",
      "Epoch 56/150\n",
      "16700/16700 [==============================] - 176s 11ms/step - loss: 84340.1035 - val_loss: 83863.7988\n",
      "Epoch 57/150\n",
      "16700/16700 [==============================] - 166s 10ms/step - loss: 84222.8037 - val_loss: 83719.7591\n",
      "Epoch 58/150\n",
      "16700/16700 [==============================] - 166s 10ms/step - loss: 84103.8897 - val_loss: 83593.7684\n",
      "Epoch 59/150\n",
      "16700/16700 [==============================] - 168s 10ms/step - loss: 83985.0826 - val_loss: 83456.9422\n",
      "Epoch 60/150\n",
      "16700/16700 [==============================] - 171s 10ms/step - loss: 83863.9687 - val_loss: 83320.5956\n",
      "Epoch 61/150\n",
      "16700/16700 [==============================] - 164s 10ms/step - loss: 83752.9686 - val_loss: 83210.1479\n",
      "Epoch 62/150\n",
      "16700/16700 [==============================] - 175s 10ms/step - loss: 83644.3240 - val_loss: 83079.4717\n",
      "Epoch 63/150\n",
      "16700/16700 [==============================] - 163s 10ms/step - loss: 83517.1735 - val_loss: 82964.9646\n",
      "Epoch 64/150\n",
      "16700/16700 [==============================] - 174s 10ms/step - loss: 83426.1954 - val_loss: 82841.5300\n",
      "Epoch 65/150\n",
      "16700/16700 [==============================] - 164s 10ms/step - loss: 83317.1023 - val_loss: 82709.5398\n",
      "Epoch 66/150\n",
      "16700/16700 [==============================] - 175s 10ms/step - loss: 83199.4495 - val_loss: 82589.0115\n",
      "Epoch 67/150\n",
      "16700/16700 [==============================] - 170s 10ms/step - loss: 83107.2277 - val_loss: 82465.0319\n",
      "Epoch 68/150\n",
      "16700/16700 [==============================] - 169s 10ms/step - loss: 83002.2466 - val_loss: 82345.8586\n",
      "Epoch 69/150\n",
      "16700/16700 [==============================] - 165s 10ms/step - loss: 82911.7454 - val_loss: 82237.1777\n",
      "Epoch 70/150\n",
      "16700/16700 [==============================] - 176s 11ms/step - loss: 82803.8195 - val_loss: 82117.9931\n",
      "Epoch 71/150\n",
      "16700/16700 [==============================] - 172s 10ms/step - loss: 82692.0594 - val_loss: 82006.6477\n",
      "Epoch 72/150\n",
      "16700/16700 [==============================] - 169s 10ms/step - loss: 82585.7078 - val_loss: 81893.5675\n",
      "Epoch 73/150\n",
      "16700/16700 [==============================] - 175s 10ms/step - loss: 82508.2131 - val_loss: 81791.4273\n",
      "Epoch 74/150\n",
      "16700/16700 [==============================] - 170s 10ms/step - loss: 82392.9489 - val_loss: 81672.2067\n",
      "Epoch 75/150\n",
      "16700/16700 [==============================] - 175s 10ms/step - loss: 82307.7673 - val_loss: 81585.8147\n",
      "Epoch 76/150\n",
      "16700/16700 [==============================] - 175s 10ms/step - loss: 82226.2247 - val_loss: 81476.7907\n",
      "Epoch 77/150\n",
      "16700/16700 [==============================] - 166s 10ms/step - loss: 82125.1147 - val_loss: 81368.8004\n",
      "Epoch 78/150\n",
      "16700/16700 [==============================] - 174s 10ms/step - loss: 82031.6634 - val_loss: 81263.9803\n",
      "Epoch 79/150\n",
      "16700/16700 [==============================] - 160s 10ms/step - loss: 81922.3175 - val_loss: 81158.9646\n",
      "Epoch 80/150\n",
      "16700/16700 [==============================] - 181s 11ms/step - loss: 81849.9511 - val_loss: 81067.3604\n",
      "Epoch 81/150\n",
      "16700/16700 [==============================] - 164s 10ms/step - loss: 81747.7728 - val_loss: 80957.6085\n",
      "Epoch 82/150\n",
      "16700/16700 [==============================] - 178s 11ms/step - loss: 81687.3578 - val_loss: 80869.4545\n",
      "Epoch 83/150\n",
      "16700/16700 [==============================] - 175s 10ms/step - loss: 81581.8480 - val_loss: 80765.4169\n",
      "Epoch 84/150\n",
      "16700/16700 [==============================] - 171s 10ms/step - loss: 81508.9985 - val_loss: 80666.7799\n",
      "Epoch 85/150\n",
      "16700/16700 [==============================] - 179s 11ms/step - loss: 81427.4175 - val_loss: 80554.1791\n",
      "Epoch 86/150\n",
      "16700/16700 [==============================] - 162s 10ms/step - loss: 81316.5056 - val_loss: 80465.0539\n",
      "Epoch 87/150\n",
      "16700/16700 [==============================] - 179s 11ms/step - loss: 81244.0756 - val_loss: 80373.0980\n",
      "Epoch 88/150\n",
      "16700/16700 [==============================] - 163s 10ms/step - loss: 81163.5018 - val_loss: 80287.5339\n",
      "Epoch 89/150\n",
      "16700/16700 [==============================] - 167s 10ms/step - loss: 81095.0303 - val_loss: 80201.4068\n",
      "Epoch 90/150\n",
      "16700/16700 [==============================] - 173s 10ms/step - loss: 81010.6196 - val_loss: 80094.3567\n",
      "Epoch 91/150\n",
      "16700/16700 [==============================] - 172s 10ms/step - loss: 80897.1959 - val_loss: 79987.2503\n",
      "Epoch 92/150\n",
      "16700/16700 [==============================] - 175s 10ms/step - loss: 80811.4177 - val_loss: 79910.5109\n",
      "Epoch 93/150\n",
      "16700/16700 [==============================] - 172s 10ms/step - loss: 80762.1011 - val_loss: 79815.5500\n",
      "Epoch 94/150\n",
      "16700/16700 [==============================] - 171s 10ms/step - loss: 80663.7875 - val_loss: 79702.3199\n",
      "Epoch 95/150\n",
      "16700/16700 [==============================] - 169s 10ms/step - loss: 80585.8978 - val_loss: 79619.6868\n",
      "Epoch 96/150\n",
      "16700/16700 [==============================] - 172s 10ms/step - loss: 80502.4991 - val_loss: 79512.7621\n",
      "Epoch 97/150\n",
      "16700/16700 [==============================] - 170s 10ms/step - loss: 80430.0367 - val_loss: 79423.2947\n",
      "Epoch 98/150\n",
      "16700/16700 [==============================] - 171s 10ms/step - loss: 80371.3566 - val_loss: 79331.9491\n",
      "Epoch 99/150\n",
      "16700/16700 [==============================] - 188s 11ms/step - loss: 80258.3004 - val_loss: 79244.9694\n",
      "Epoch 100/150\n",
      "16700/16700 [==============================] - 171s 10ms/step - loss: 80173.9296 - val_loss: 79152.7026\n",
      "Epoch 101/150\n",
      "16700/16700 [==============================] - 171s 10ms/step - loss: 80128.1550 - val_loss: 79062.9668\n",
      "Epoch 102/150\n",
      "16700/16700 [==============================] - 171s 10ms/step - loss: 80052.5510 - val_loss: 78972.4324\n",
      "Epoch 103/150\n",
      "16700/16700 [==============================] - 175s 10ms/step - loss: 79993.8845 - val_loss: 78889.0289\n",
      "Epoch 104/150\n",
      "16700/16700 [==============================] - 157s 9ms/step - loss: 79887.6504 - val_loss: 78803.7599\n",
      "Epoch 105/150\n",
      "16700/16700 [==============================] - 172s 10ms/step - loss: 79824.6273 - val_loss: 78729.5290\n",
      "Epoch 106/150\n",
      "16700/16700 [==============================] - 173s 10ms/step - loss: 79761.4278 - val_loss: 78640.4312\n",
      "Epoch 107/150\n",
      "16700/16700 [==============================] - 168s 10ms/step - loss: 79681.5324 - val_loss: 78559.0748\n",
      "Epoch 108/150\n",
      "16700/16700 [==============================] - 172s 10ms/step - loss: 79622.5538 - val_loss: 78479.6065\n",
      "Epoch 109/150\n",
      "16700/16700 [==============================] - 160s 10ms/step - loss: 79528.8313 - val_loss: 78402.5003\n",
      "Epoch 110/150\n",
      "16700/16700 [==============================] - 174s 10ms/step - loss: 79485.7966 - val_loss: 78323.4669\n",
      "Epoch 111/150\n",
      "16700/16700 [==============================] - 168s 10ms/step - loss: 79422.0027 - val_loss: 78230.0774\n",
      "Epoch 112/150\n",
      "16700/16700 [==============================] - 173s 10ms/step - loss: 79361.5957 - val_loss: 78146.4305\n",
      "Epoch 113/150\n",
      "16700/16700 [==============================] - 172s 10ms/step - loss: 79280.4737 - val_loss: 78078.0090\n",
      "Epoch 114/150\n",
      "16700/16700 [==============================] - 162s 10ms/step - loss: 79177.1199 - val_loss: 77993.0704\n",
      "Epoch 115/150\n",
      "16700/16700 [==============================] - 165s 10ms/step - loss: 79142.3302 - val_loss: 77909.2192\n",
      "Epoch 116/150\n",
      "16700/16700 [==============================] - 174s 10ms/step - loss: 79092.0041 - val_loss: 77830.7141\n",
      "Epoch 117/150\n",
      "16700/16700 [==============================] - 169s 10ms/step - loss: 78992.9655 - val_loss: 77755.0318\n",
      "Epoch 118/150\n",
      "16700/16700 [==============================] - 176s 11ms/step - loss: 78926.3550 - val_loss: 77707.8995\n",
      "Epoch 119/150\n",
      "16700/16700 [==============================] - 159s 10ms/step - loss: 78887.7809 - val_loss: 77623.1184\n",
      "Epoch 120/150\n",
      "16700/16700 [==============================] - 167s 10ms/step - loss: 78803.4990 - val_loss: 77534.8735\n",
      "Epoch 121/150\n",
      "16700/16700 [==============================] - 179s 11ms/step - loss: 78700.0431 - val_loss: 77467.8050\n",
      "Epoch 122/150\n",
      "16700/16700 [==============================] - 162s 10ms/step - loss: 78690.6669 - val_loss: 77380.0598\n",
      "Epoch 123/150\n",
      "16700/16700 [==============================] - 170s 10ms/step - loss: 78613.6908 - val_loss: 77291.6457\n",
      "Epoch 124/150\n",
      "16700/16700 [==============================] - 171s 10ms/step - loss: 78540.0912 - val_loss: 77191.3570\n",
      "Epoch 125/150\n",
      "16700/16700 [==============================] - 175s 11ms/step - loss: 78457.2849 - val_loss: 77105.2090\n",
      "Epoch 126/150\n",
      "16700/16700 [==============================] - 176s 11ms/step - loss: 78397.3885 - val_loss: 77036.6760\n",
      "Epoch 127/150\n",
      "16700/16700 [==============================] - 175s 10ms/step - loss: 78303.1478 - val_loss: 76955.5204\n",
      "Epoch 128/150\n",
      "16700/16700 [==============================] - 166s 10ms/step - loss: 78242.6135 - val_loss: 76874.7318\n",
      "Epoch 129/150\n",
      "16700/16700 [==============================] - 173s 10ms/step - loss: 78194.9778 - val_loss: 76806.1949\n",
      "Epoch 130/150\n",
      "16700/16700 [==============================] - 175s 11ms/step - loss: 78124.7058 - val_loss: 76732.9713\n",
      "Epoch 131/150\n",
      "16700/16700 [==============================] - 165s 10ms/step - loss: 78003.8720 - val_loss: 76660.2033\n",
      "Epoch 132/150\n",
      "16700/16700 [==============================] - 175s 10ms/step - loss: 78001.2930 - val_loss: 76593.0326\n",
      "Epoch 133/150\n",
      "16700/16700 [==============================] - 174s 10ms/step - loss: 77928.0857 - val_loss: 76517.8870\n",
      "Epoch 134/150\n",
      "16700/16700 [==============================] - 169s 10ms/step - loss: 77855.7302 - val_loss: 76433.1498\n",
      "Epoch 135/150\n",
      "16700/16700 [==============================] - 168s 10ms/step - loss: 77786.7655 - val_loss: 76357.6533\n",
      "Epoch 136/150\n",
      "16700/16700 [==============================] - 179s 11ms/step - loss: 77763.6157 - val_loss: 76296.2986\n",
      "Epoch 137/150\n",
      "16700/16700 [==============================] - 159s 10ms/step - loss: 77647.4803 - val_loss: 76215.0031\n",
      "Epoch 138/150\n",
      "16700/16700 [==============================] - 169s 10ms/step - loss: 77621.8290 - val_loss: 76156.3070\n",
      "Epoch 139/150\n",
      "16700/16700 [==============================] - 175s 10ms/step - loss: 77529.7901 - val_loss: 76075.8601\n",
      "Epoch 140/150\n",
      "16700/16700 [==============================] - 171s 10ms/step - loss: 77451.6148 - val_loss: 76019.0778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/150\n",
      "16700/16700 [==============================] - 189s 11ms/step - loss: 77434.9829 - val_loss: 75933.5434\n",
      "Epoch 142/150\n",
      "16700/16700 [==============================] - 171s 10ms/step - loss: 77325.3025 - val_loss: 75870.5387\n",
      "Epoch 143/150\n",
      "16700/16700 [==============================] - 188s 11ms/step - loss: 77311.4499 - val_loss: 75786.2495\n",
      "Epoch 144/150\n",
      "16700/16700 [==============================] - 172s 10ms/step - loss: 77244.7348 - val_loss: 75727.9122\n",
      "Epoch 145/150\n",
      "16700/16700 [==============================] - 179s 11ms/step - loss: 77195.1078 - val_loss: 75666.6012\n",
      "Epoch 146/150\n",
      "16700/16700 [==============================] - 174s 10ms/step - loss: 77150.1383 - val_loss: 75609.0007\n",
      "Epoch 147/150\n",
      "16700/16700 [==============================] - 170s 10ms/step - loss: 77078.2199 - val_loss: 75531.6737\n",
      "Epoch 148/150\n",
      "16700/16700 [==============================] - 171s 10ms/step - loss: 77008.4259 - val_loss: 75472.1816\n",
      "Epoch 149/150\n",
      "16700/16700 [==============================] - 170s 10ms/step - loss: 76949.8233 - val_loss: 75430.3023\n",
      "Epoch 150/150\n",
      "14176/16700 [========================>.....] - ETA: 25s - loss: 76947.0063"
     ]
    }
   ],
   "source": [
    "nb_epoch = 150\n",
    "batch_size = 32\n",
    "\n",
    "autoencoder.compile(optimizer='adam', \n",
    "                    loss='mean_squared_error')\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=\"4_6_autoencoder.h5\",\n",
    "                               verbose=0,\n",
    "                               save_best_only=True)\n",
    "\n",
    "earlystopping = EarlyStopping(monitor='val_loss', patience=2, verbose=0) # 'patience' number of not improving epochs\n",
    "\n",
    "history = autoencoder.fit(X_train_split, X_train_split,\n",
    "                    epochs=nb_epoch,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(X_valid_split, X_valid_split),\n",
    "                    verbose=1,\n",
    "                    callbacks=[checkpointer, #tensorboard, \n",
    "                               earlystopping]).history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model not finished, it's still not converge and the val_loss is still decreasing for 150 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = load_model('4_6_autoencoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('base': conda)",
   "language": "python",
   "name": "python37064bitbaseconda4e1999c9094b42c0ba2c4ed1fdd74390"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
